{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2_ADA_Image-Creation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9t_QF6fA8Xqt",
        "rx-6f90j8or6",
        "E4XMoEwNn0u_"
      ],
      "authorship_tag": "ABX9TyN32LbfcXQHut/zPtLrBX0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hochthom/OG-AI4Artists-2022/blob/main/Image_Generation/StyleGAN2_ADA_Image_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Images with StyleGAN2 on Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "2BLQf9vV1mZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we check for what GPU we have been assigned."
      ],
      "metadata": {
        "id": "vX5cNdvj3AuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJIGIZ0R1lFF",
        "outputId": "0623157e-33d8-40cf-a8f8-8374ad561327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-cd474c45-2988-8a80-bf84-1e298348f391)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we connect to Google drive account:"
      ],
      "metadata": {
        "id": "bb0eecj73Dvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqoFvnYZ2Kzy",
        "outputId": "358d5c9c-3f8c-4bd4-cf55-db739914c449"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kopih-124PSs",
        "outputId": "c98582a3-b031-47a6-807c-19bba96c8479"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "_eEwhvCue1ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja opensimplex torch==1.7.1 torchvision==0.8.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-2gaQ4uHz-i",
        "outputId": "63da459e-9353-4c9e-f57f-8b6a57b66d3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 36.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 39.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 38.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 28.5 MB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.4.2-py3-none-any.whl (17 kB)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 18 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, opensimplex, ninja\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed ninja-1.10.2.3 opensimplex-0.4.2 torch-1.7.1 torchvision-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install StyleGAN2 Repo"
      ],
      "metadata": {
        "id": "mlrMOMTb5GJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HOME_DIR = '/content/drive/MyDrive/AI4Artists/OG-AI4Artists-2022'\n",
        "!ls $HOME_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKEn89ps3bKy",
        "outputId": "cd92f151-dc6c-449d-e3f3-3e24070e42fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'AI for Artists - Img-Gen.gslides'    notebooks\n",
            "'AI for Artists - Intro.gslides'      stylegan2-ada-pytorch\n",
            "'AI for Artists - Text-Gen.gslides'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "sg2_dir = os.path.join(HOME_DIR, 'stylegan2-ada-pytorch')\n",
        "if os.path.isdir(sg2_dir):\n",
        "    %cd $sg2_dir\n",
        "elif os.path.isdir(HOME_DIR):\n",
        "    #install script\n",
        "    %cd $HOME_DIR\n",
        "    !git clone https://github.com/hochthom/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !mkdir samples\n",
        "else:\n",
        "  print('Set valid directory for HOME_DIR!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmDlm1Kb4_B0",
        "outputId": "1b021a91-7af2-48e7-cf5e-a136befff44c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI4Artists/OG-AI4Artists-2022/stylegan2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "s7crSGxs6ydE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Preparation\n",
        "Upload your model (*.pkl file) into the pretrained folder in your local repo (the one we just generated) or train a model from scratch (see other notebook).\n",
        "\n",
        "You can use also a pretrained model from this awesome list: \n",
        "https://github.com/justinpinkney/awesome-pretrained-stylegan2"
      ],
      "metadata": {
        "id": "9t_QF6fA8Xqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Creation\n",
        "First we have to set some variables ...\n",
        "\n",
        "* `dataset_path`: this is the path to your .zip file\n",
        "* `resume_from`: if you’re starting a new dataset I recommend `'ffhq256'` or `'./pretrained/wikiart.pkl'`\n"
      ],
      "metadata": {
        "id": "rx-6f90j8or6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#required: definitely edit these!\n",
        "#model = './pretrained/StyleGAN2_metFaces_res1024.pkl'  # humane faces from art works\n",
        "model = './pretrained/StyleGAN2_ffhq_res512.pkl'        # flickr faces high quality\n",
        "outdir = './samples'\n",
        "\n",
        "if not os.path.isdir(outdir):\n",
        "  print('Warning: Could not find directory for saving generated images!')"
      ],
      "metadata": {
        "id": "G-QTs4tt8nGh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see all available parameters for training you can execute the following code"
      ],
      "metadata": {
        "id": "JpFab8UN945G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --help"
      ],
      "metadata": {
        "id": "Eh8EEpLZ-HBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally the code for generting images :)"
      ],
      "metadata": {
        "id": "bg0wMe8Pe-1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=$outdir --trunc=0.8 --seeds=0-5 --network=$model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3VYTfnmEk-Y",
        "outputId": "4a0acef8-8b44-4969-fb52-a4ab34fafe73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"./pretrained/StyleGAN2_ffhq_res512.pkl\"...\n",
            "Generating image for seed 0 (0/6) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for seed 1 (1/6) ...\n",
            "Generating image for seed 2 (2/6) ...\n",
            "Generating image for seed 3 (3/6) ...\n",
            "Generating image for seed 4 (4/6) ...\n",
            "Generating image for seed 5 (5/6) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "yuDRxcVEt7VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Truncation\n",
        "What is the influence of the truncation parameter? A value between -1 to 1 will give pretty realistic images. But the higher the value we set, the weirder it gets."
      ],
      "metadata": {
        "id": "E4XMoEwNn0u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=$outdir --process=\"truncation\" --start=-0.5 --stop=3 --increment=0.02 --seeds=5 --network=$model"
      ],
      "metadata": {
        "id": "rOcmHc4gn_c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolation\n",
        "Starting from one image, we want to gradually move to another image ( akind of morphing effect). We can define the sequence with our seed parameter. The number of frames per interpolation can be set with the *--frames* parameter. E.g. for *--seed=1,5,1* the number of frames will be two times the *--frames* value (from 1 to 5 and back to 1)! "
      ],
      "metadata": {
        "id": "bvEhZW4VoGck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=$outdir --process=\"interpolation\" --frames=100 --trunc=0.8 --seeds=0,5 --network=$model"
      ],
      "metadata": {
        "id": "u20rmUj8r6rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other fun way of interpolation is through a **noise / circular loop** in the latent space of the model. You can control the diversity of the generated samples with the *--diameter* parameter. Circle loop needs higher values (100) than noise loop (1) but good values also strongly depend on the used model!"
      ],
      "metadata": {
        "id": "6xlqe3OHxFXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=$outdir --process=\"interpolation\" --interpolation=\"circularloop\" --diameter=100 --frames=240 --trunc=0.8 --random_seed=0 --network=$model"
      ],
      "metadata": {
        "id": "UjVOH87Dxnn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projection\n",
        "Is the process to find a vector that generates an image that is perceptionally close to the given one.\n",
        "\n",
        "*   `--target`: this is a path to the image file that we want to \"find\" with our model. This image must be the exact same size as the images used for training the model.\n",
        "*   `--num-steps`: how many iterations the projector should use to find a good projection. Higher values will take longer but will likely find better fitting images."
      ],
      "metadata": {
        "id": "JeQXOsKXI0RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python projector.py --help"
      ],
      "metadata": {
        "id": "VFmYUJ3TJ24o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = './downloads/art-hauntington-unsplash-512.jpg'\n",
        "#target = './downloads/mathias-konrath-unsplash_512.jpg'"
      ],
      "metadata": {
        "id": "ImlKm3Vg91cM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python projector.py --outdir=$outdir --target=$target --num-steps=200 --seed=0 --network=$model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXcvlEV6KN7w",
        "outputId": "5c853f4c-29d6-4020-e491-5b705c38f2cf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"./pretrained/StyleGAN2_ffhq_res512.pkl\"...\n",
            "Computing W midpoint and stddev using 10000 samples...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "step    1/200: dist 0.60 loss 9557.81\n",
            "step    2/200: dist 0.57 loss 13249.50\n",
            "step    3/200: dist 0.51 loss 11521.82\n",
            "step    4/200: dist 0.57 loss 8737.99\n",
            "step    5/200: dist 0.45 loss 5736.14\n",
            "step    6/200: dist 0.49 loss 3210.26\n",
            "step    7/200: dist 0.39 loss 2003.14\n",
            "step    8/200: dist 0.46 loss 2411.67\n",
            "step    9/200: dist 0.48 loss 4028.77\n",
            "step   10/200: dist 0.36 loss 5837.86\n",
            "step   11/200: dist 0.34 loss 6856.03\n",
            "step   12/200: dist 0.39 loss 6585.55\n",
            "step   13/200: dist 0.38 loss 5787.26\n",
            "step   14/200: dist 0.33 loss 4627.46\n",
            "step   15/200: dist 0.38 loss 3462.34\n",
            "step   16/200: dist 0.33 loss 2563.82\n",
            "step   17/200: dist 0.34 loss 2089.59\n",
            "step   18/200: dist 0.36 loss 1789.95\n",
            "step   19/200: dist 0.36 loss 1552.74\n",
            "step   20/200: dist 0.36 loss 1498.76\n",
            "step   21/200: dist 0.37 loss 1582.63\n",
            "step   22/200: dist 0.32 loss 1601.39\n",
            "step   23/200: dist 0.34 loss 1509.56\n",
            "step   24/200: dist 0.33 loss 1399.24\n",
            "step   25/200: dist 0.32 loss 1370.67\n",
            "step   26/200: dist 0.32 loss 1324.31\n",
            "step   27/200: dist 0.29 loss 1196.95\n",
            "step   28/200: dist 0.29 loss 996.46\n",
            "step   29/200: dist 0.27 loss 779.03\n",
            "step   30/200: dist 0.32 loss 588.03\n",
            "step   31/200: dist 0.28 loss 442.80\n",
            "step   32/200: dist 0.28 loss 352.92\n",
            "step   33/200: dist 0.27 loss 330.41\n",
            "step   34/200: dist 0.30 loss 386.31\n",
            "step   35/200: dist 0.27 loss 447.46\n",
            "step   36/200: dist 0.27 loss 489.18\n",
            "step   37/200: dist 0.28 loss 496.19\n",
            "step   38/200: dist 0.28 loss 436.06\n",
            "step   39/200: dist 0.28 loss 343.11\n",
            "step   40/200: dist 0.27 loss 255.36\n",
            "step   41/200: dist 0.27 loss 178.67\n",
            "step   42/200: dist 0.26 loss 125.19\n",
            "step   43/200: dist 0.27 loss 110.56\n",
            "step   44/200: dist 0.26 loss 138.67\n",
            "step   45/200: dist 0.26 loss 172.42\n",
            "step   46/200: dist 0.24 loss 183.48\n",
            "step   47/200: dist 0.25 loss 166.97\n",
            "step   48/200: dist 0.26 loss 140.31\n",
            "step   49/200: dist 0.25 loss 108.93\n",
            "step   50/200: dist 0.28 loss 83.10\n",
            "step   51/200: dist 0.25 loss 73.12\n",
            "step   52/200: dist 0.26 loss 78.76\n",
            "step   53/200: dist 0.23 loss 78.72\n",
            "step   54/200: dist 0.25 loss 67.55\n",
            "step   55/200: dist 0.25 loss 58.18\n",
            "step   56/200: dist 0.24 loss 53.93\n",
            "step   57/200: dist 0.26 loss 49.06\n",
            "step   58/200: dist 0.26 loss 42.12\n",
            "step   59/200: dist 0.28 loss 38.77\n",
            "step   60/200: dist 0.26 loss 34.83\n",
            "step   61/200: dist 0.26 loss 30.54\n",
            "step   62/200: dist 0.25 loss 27.69\n",
            "step   63/200: dist 0.24 loss 29.82\n",
            "step   64/200: dist 0.24 loss 32.93\n",
            "step   65/200: dist 0.23 loss 29.79\n",
            "step   66/200: dist 0.23 loss 22.02\n",
            "step   67/200: dist 0.23 loss 14.83\n",
            "step   68/200: dist 0.23 loss 9.83 \n",
            "step   69/200: dist 0.25 loss 8.52 \n",
            "step   70/200: dist 0.24 loss 10.78\n",
            "step   71/200: dist 0.23 loss 14.33\n",
            "step   72/200: dist 0.22 loss 15.39\n",
            "step   73/200: dist 0.23 loss 14.08\n",
            "step   74/200: dist 0.22 loss 12.48\n",
            "step   75/200: dist 0.22 loss 12.94\n",
            "step   76/200: dist 0.22 loss 14.19\n",
            "step   77/200: dist 0.22 loss 14.35\n",
            "step   78/200: dist 0.22 loss 13.97\n",
            "step   79/200: dist 0.22 loss 13.72\n",
            "step   80/200: dist 0.22 loss 13.18\n",
            "step   81/200: dist 0.23 loss 14.82\n",
            "step   82/200: dist 0.22 loss 15.60\n",
            "step   83/200: dist 0.23 loss 10.06\n",
            "step   84/200: dist 0.22 loss 6.05 \n",
            "step   85/200: dist 0.22 loss 9.68 \n",
            "step   86/200: dist 0.22 loss 11.67\n",
            "step   87/200: dist 0.22 loss 7.30 \n",
            "step   88/200: dist 0.21 loss 5.96 \n",
            "step   89/200: dist 0.22 loss 7.06 \n",
            "step   90/200: dist 0.22 loss 4.69 \n",
            "step   91/200: dist 0.21 loss 3.55 \n",
            "step   92/200: dist 0.21 loss 4.80 \n",
            "step   93/200: dist 0.22 loss 3.09 \n",
            "step   94/200: dist 0.22 loss 2.37 \n",
            "step   95/200: dist 0.21 loss 5.09 \n",
            "step   96/200: dist 0.21 loss 4.46 \n",
            "step   97/200: dist 0.21 loss 1.69 \n",
            "step   98/200: dist 0.20 loss 2.62 \n",
            "step   99/200: dist 0.21 loss 3.64 \n",
            "step  100/200: dist 0.20 loss 2.08 \n",
            "step  101/200: dist 0.21 loss 1.85 \n",
            "step  102/200: dist 0.20 loss 2.91 \n",
            "step  103/200: dist 0.20 loss 3.03 \n",
            "step  104/200: dist 0.20 loss 3.72 \n",
            "step  105/200: dist 0.20 loss 4.80 \n",
            "step  106/200: dist 0.20 loss 4.16 \n",
            "step  107/200: dist 0.21 loss 2.79 \n",
            "step  108/200: dist 0.20 loss 2.30 \n",
            "step  109/200: dist 0.20 loss 2.31 \n",
            "step  110/200: dist 0.20 loss 2.94 \n",
            "step  111/200: dist 0.20 loss 4.39 \n",
            "step  112/200: dist 0.21 loss 4.93 \n",
            "step  113/200: dist 0.20 loss 3.66 \n",
            "step  114/200: dist 0.20 loss 2.10 \n",
            "step  115/200: dist 0.20 loss 1.48 \n",
            "step  116/200: dist 0.20 loss 1.47 \n",
            "step  117/200: dist 0.20 loss 1.68 \n",
            "step  118/200: dist 0.20 loss 2.01 \n",
            "step  119/200: dist 0.20 loss 2.11 \n",
            "step  120/200: dist 0.20 loss 1.76 \n",
            "step  121/200: dist 0.20 loss 1.34 \n",
            "step  122/200: dist 0.20 loss 1.19 \n",
            "step  123/200: dist 0.20 loss 1.20 \n",
            "step  124/200: dist 0.20 loss 1.29 \n",
            "step  125/200: dist 0.20 loss 1.61 \n",
            "step  126/200: dist 0.20 loss 2.05 \n",
            "step  127/200: dist 0.20 loss 2.44 \n",
            "step  128/200: dist 0.20 loss 2.91 \n",
            "step  129/200: dist 0.19 loss 3.63 \n",
            "step  130/200: dist 0.19 loss 4.09 \n",
            "step  131/200: dist 0.19 loss 3.43 \n",
            "step  132/200: dist 0.19 loss 1.87 \n",
            "step  133/200: dist 0.19 loss 0.87 \n",
            "step  134/200: dist 0.19 loss 1.21 \n",
            "step  135/200: dist 0.19 loss 2.14 \n",
            "step  136/200: dist 0.19 loss 2.48 \n",
            "step  137/200: dist 0.19 loss 2.06 \n",
            "step  138/200: dist 0.19 loss 2.08 \n",
            "step  139/200: dist 0.19 loss 3.82 \n",
            "step  140/200: dist 0.19 loss 7.42 \n",
            "step  141/200: dist 0.19 loss 11.87\n",
            "step  142/200: dist 0.19 loss 15.14\n",
            "step  143/200: dist 0.20 loss 15.79\n",
            "step  144/200: dist 0.20 loss 15.81\n",
            "step  145/200: dist 0.20 loss 13.82\n",
            "step  146/200: dist 0.19 loss 8.09 \n",
            "step  147/200: dist 0.19 loss 6.38 \n",
            "step  148/200: dist 0.19 loss 9.23 \n",
            "step  149/200: dist 0.19 loss 7.95 \n",
            "step  150/200: dist 0.19 loss 4.41 \n",
            "step  151/200: dist 0.19 loss 7.44 \n",
            "step  152/200: dist 0.19 loss 10.36\n",
            "step  153/200: dist 0.19 loss 7.78 \n",
            "step  154/200: dist 0.19 loss 10.06\n",
            "step  155/200: dist 0.19 loss 14.96\n",
            "step  156/200: dist 0.19 loss 9.28 \n",
            "step  157/200: dist 0.19 loss 2.32 \n",
            "step  158/200: dist 0.19 loss 4.61 \n",
            "step  159/200: dist 0.19 loss 5.88 \n",
            "step  160/200: dist 0.20 loss 4.02 \n",
            "step  161/200: dist 0.19 loss 3.29 \n",
            "step  162/200: dist 0.19 loss 2.01 \n",
            "step  163/200: dist 0.19 loss 2.99 \n",
            "step  164/200: dist 0.19 loss 2.74 \n",
            "step  165/200: dist 0.19 loss 0.87 \n",
            "step  166/200: dist 0.19 loss 2.43 \n",
            "step  167/200: dist 0.19 loss 1.19 \n",
            "step  168/200: dist 0.19 loss 1.09 \n",
            "step  169/200: dist 0.19 loss 1.50 \n",
            "step  170/200: dist 0.19 loss 0.56 \n",
            "step  171/200: dist 0.19 loss 1.21 \n",
            "step  172/200: dist 0.19 loss 0.52 \n",
            "step  173/200: dist 0.19 loss 0.84 \n",
            "step  174/200: dist 0.19 loss 0.52 \n",
            "step  175/200: dist 0.19 loss 0.60 \n",
            "step  176/200: dist 0.19 loss 0.48 \n",
            "step  177/200: dist 0.19 loss 0.46 \n",
            "step  178/200: dist 0.19 loss 0.40 \n",
            "step  179/200: dist 0.19 loss 0.41 \n",
            "step  180/200: dist 0.19 loss 0.30 \n",
            "step  181/200: dist 0.19 loss 0.38 \n",
            "step  182/200: dist 0.19 loss 0.27 \n",
            "step  183/200: dist 0.19 loss 0.27 \n",
            "step  184/200: dist 0.19 loss 0.31 \n",
            "step  185/200: dist 0.18 loss 0.23 \n",
            "step  186/200: dist 0.18 loss 0.22 \n",
            "step  187/200: dist 0.18 loss 0.26 \n",
            "step  188/200: dist 0.18 loss 0.23 \n",
            "step  189/200: dist 0.18 loss 0.19 \n",
            "step  190/200: dist 0.18 loss 0.20 \n",
            "step  191/200: dist 0.18 loss 0.22 \n",
            "step  192/200: dist 0.18 loss 0.22 \n",
            "step  193/200: dist 0.18 loss 0.20 \n",
            "step  194/200: dist 0.18 loss 0.19 \n",
            "step  195/200: dist 0.18 loss 0.18 \n",
            "step  196/200: dist 0.18 loss 0.18 \n",
            "step  197/200: dist 0.18 loss 0.19 \n",
            "step  198/200: dist 0.18 loss 0.19 \n",
            "step  199/200: dist 0.18 loss 0.19 \n",
            "step  200/200: dist 0.18 loss 0.19 \n",
            "Elapsed: 24.5 s\n",
            "Saving optimization progress video \"./samples/proj.mp4\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For interpolation we first have to combine the generated projection files (*.npz)."
      ],
      "metadata": {
        "id": "bkO_ccxOC17F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python combine_npz.py --outdir=$outdir --npzs='./samples/woman.npz,./samples/old_man.npz'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tue6RBiAC02Z",
        "outputId": "9e9236d3-84bb-4c01-f7aa-59ddcaa83981"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combining .npz files...\n",
            "./samples/woman.npz\n",
            "./samples/old_man.npz\n",
            "torch.Size([2, 16, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=$outdir --process=interpolation --frames=240 --space=w --projected-w=./samples/combined.npz --network=$model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQnr3QpwDeqC",
        "outputId": "c1296d12-6639-4071-e037-d944a27c247f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"./pretrained/StyleGAN2_ffhq_res512.pkl\"...\n",
            "Generating image for frame 0/240 ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for frame 1/240 ...\n",
            "Generating image for frame 2/240 ...\n",
            "Generating image for frame 3/240 ...\n",
            "Generating image for frame 4/240 ...\n",
            "Generating image for frame 5/240 ...\n",
            "Generating image for frame 6/240 ...\n",
            "Generating image for frame 7/240 ...\n",
            "Generating image for frame 8/240 ...\n",
            "Generating image for frame 9/240 ...\n",
            "Generating image for frame 10/240 ...\n",
            "Generating image for frame 11/240 ...\n",
            "Generating image for frame 12/240 ...\n",
            "Generating image for frame 13/240 ...\n",
            "Generating image for frame 14/240 ...\n",
            "Generating image for frame 15/240 ...\n",
            "Generating image for frame 16/240 ...\n",
            "Generating image for frame 17/240 ...\n",
            "Generating image for frame 18/240 ...\n",
            "Generating image for frame 19/240 ...\n",
            "Generating image for frame 20/240 ...\n",
            "Generating image for frame 21/240 ...\n",
            "Generating image for frame 22/240 ...\n",
            "Generating image for frame 23/240 ...\n",
            "Generating image for frame 24/240 ...\n",
            "Generating image for frame 25/240 ...\n",
            "Generating image for frame 26/240 ...\n",
            "Generating image for frame 27/240 ...\n",
            "Generating image for frame 28/240 ...\n",
            "Generating image for frame 29/240 ...\n",
            "Generating image for frame 30/240 ...\n",
            "Generating image for frame 31/240 ...\n",
            "Generating image for frame 32/240 ...\n",
            "Generating image for frame 33/240 ...\n",
            "Generating image for frame 34/240 ...\n",
            "Generating image for frame 35/240 ...\n",
            "Generating image for frame 36/240 ...\n",
            "Generating image for frame 37/240 ...\n",
            "Generating image for frame 38/240 ...\n",
            "Generating image for frame 39/240 ...\n",
            "Generating image for frame 40/240 ...\n",
            "Generating image for frame 41/240 ...\n",
            "Generating image for frame 42/240 ...\n",
            "Generating image for frame 43/240 ...\n",
            "Generating image for frame 44/240 ...\n",
            "Generating image for frame 45/240 ...\n",
            "Generating image for frame 46/240 ...\n",
            "Generating image for frame 47/240 ...\n",
            "Generating image for frame 48/240 ...\n",
            "Generating image for frame 49/240 ...\n",
            "Generating image for frame 50/240 ...\n",
            "Generating image for frame 51/240 ...\n",
            "Generating image for frame 52/240 ...\n",
            "Generating image for frame 53/240 ...\n",
            "Generating image for frame 54/240 ...\n",
            "Generating image for frame 55/240 ...\n",
            "Generating image for frame 56/240 ...\n",
            "Generating image for frame 57/240 ...\n",
            "Generating image for frame 58/240 ...\n",
            "Generating image for frame 59/240 ...\n",
            "Generating image for frame 60/240 ...\n",
            "Generating image for frame 61/240 ...\n",
            "Generating image for frame 62/240 ...\n",
            "Generating image for frame 63/240 ...\n",
            "Generating image for frame 64/240 ...\n",
            "Generating image for frame 65/240 ...\n",
            "Generating image for frame 66/240 ...\n",
            "Generating image for frame 67/240 ...\n",
            "Generating image for frame 68/240 ...\n",
            "Generating image for frame 69/240 ...\n",
            "Generating image for frame 70/240 ...\n",
            "Generating image for frame 71/240 ...\n",
            "Generating image for frame 72/240 ...\n",
            "Generating image for frame 73/240 ...\n",
            "Generating image for frame 74/240 ...\n",
            "Generating image for frame 75/240 ...\n",
            "Generating image for frame 76/240 ...\n",
            "Generating image for frame 77/240 ...\n",
            "Generating image for frame 78/240 ...\n",
            "Generating image for frame 79/240 ...\n",
            "Generating image for frame 80/240 ...\n",
            "Generating image for frame 81/240 ...\n",
            "Generating image for frame 82/240 ...\n",
            "Generating image for frame 83/240 ...\n",
            "Generating image for frame 84/240 ...\n",
            "Generating image for frame 85/240 ...\n",
            "Generating image for frame 86/240 ...\n",
            "Generating image for frame 87/240 ...\n",
            "Generating image for frame 88/240 ...\n",
            "Generating image for frame 89/240 ...\n",
            "Generating image for frame 90/240 ...\n",
            "Generating image for frame 91/240 ...\n",
            "Generating image for frame 92/240 ...\n",
            "Generating image for frame 93/240 ...\n",
            "Generating image for frame 94/240 ...\n",
            "Generating image for frame 95/240 ...\n",
            "Generating image for frame 96/240 ...\n",
            "Generating image for frame 97/240 ...\n",
            "Generating image for frame 98/240 ...\n",
            "Generating image for frame 99/240 ...\n",
            "Generating image for frame 100/240 ...\n",
            "Generating image for frame 101/240 ...\n",
            "Generating image for frame 102/240 ...\n",
            "Generating image for frame 103/240 ...\n",
            "Generating image for frame 104/240 ...\n",
            "Generating image for frame 105/240 ...\n",
            "Generating image for frame 106/240 ...\n",
            "Generating image for frame 107/240 ...\n",
            "Generating image for frame 108/240 ...\n",
            "Generating image for frame 109/240 ...\n",
            "Generating image for frame 110/240 ...\n",
            "Generating image for frame 111/240 ...\n",
            "Generating image for frame 112/240 ...\n",
            "Generating image for frame 113/240 ...\n",
            "Generating image for frame 114/240 ...\n",
            "Generating image for frame 115/240 ...\n",
            "Generating image for frame 116/240 ...\n",
            "Generating image for frame 117/240 ...\n",
            "Generating image for frame 118/240 ...\n",
            "Generating image for frame 119/240 ...\n",
            "Generating image for frame 120/240 ...\n",
            "Generating image for frame 121/240 ...\n",
            "Generating image for frame 122/240 ...\n",
            "Generating image for frame 123/240 ...\n",
            "Generating image for frame 124/240 ...\n",
            "Generating image for frame 125/240 ...\n",
            "Generating image for frame 126/240 ...\n",
            "Generating image for frame 127/240 ...\n",
            "Generating image for frame 128/240 ...\n",
            "Generating image for frame 129/240 ...\n",
            "Generating image for frame 130/240 ...\n",
            "Generating image for frame 131/240 ...\n",
            "Generating image for frame 132/240 ...\n",
            "Generating image for frame 133/240 ...\n",
            "Generating image for frame 134/240 ...\n",
            "Generating image for frame 135/240 ...\n",
            "Generating image for frame 136/240 ...\n",
            "Generating image for frame 137/240 ...\n",
            "Generating image for frame 138/240 ...\n",
            "Generating image for frame 139/240 ...\n",
            "Generating image for frame 140/240 ...\n",
            "Generating image for frame 141/240 ...\n",
            "Generating image for frame 142/240 ...\n",
            "Generating image for frame 143/240 ...\n",
            "Generating image for frame 144/240 ...\n",
            "Generating image for frame 145/240 ...\n",
            "Generating image for frame 146/240 ...\n",
            "Generating image for frame 147/240 ...\n",
            "Generating image for frame 148/240 ...\n",
            "Generating image for frame 149/240 ...\n",
            "Generating image for frame 150/240 ...\n",
            "Generating image for frame 151/240 ...\n",
            "Generating image for frame 152/240 ...\n",
            "Generating image for frame 153/240 ...\n",
            "Generating image for frame 154/240 ...\n",
            "Generating image for frame 155/240 ...\n",
            "Generating image for frame 156/240 ...\n",
            "Generating image for frame 157/240 ...\n",
            "Generating image for frame 158/240 ...\n",
            "Generating image for frame 159/240 ...\n",
            "Generating image for frame 160/240 ...\n",
            "Generating image for frame 161/240 ...\n",
            "Generating image for frame 162/240 ...\n",
            "Generating image for frame 163/240 ...\n",
            "Generating image for frame 164/240 ...\n",
            "Generating image for frame 165/240 ...\n",
            "Generating image for frame 166/240 ...\n",
            "Generating image for frame 167/240 ...\n",
            "Generating image for frame 168/240 ...\n",
            "Generating image for frame 169/240 ...\n",
            "Generating image for frame 170/240 ...\n",
            "Generating image for frame 171/240 ...\n",
            "Generating image for frame 172/240 ...\n",
            "Generating image for frame 173/240 ...\n",
            "Generating image for frame 174/240 ...\n",
            "Generating image for frame 175/240 ...\n",
            "Generating image for frame 176/240 ...\n",
            "Generating image for frame 177/240 ...\n",
            "Generating image for frame 178/240 ...\n",
            "Generating image for frame 179/240 ...\n",
            "Generating image for frame 180/240 ...\n",
            "Generating image for frame 181/240 ...\n",
            "Generating image for frame 182/240 ...\n",
            "Generating image for frame 183/240 ...\n",
            "Generating image for frame 184/240 ...\n",
            "Generating image for frame 185/240 ...\n",
            "Generating image for frame 186/240 ...\n",
            "Generating image for frame 187/240 ...\n",
            "Generating image for frame 188/240 ...\n",
            "Generating image for frame 189/240 ...\n",
            "Generating image for frame 190/240 ...\n",
            "Generating image for frame 191/240 ...\n",
            "Generating image for frame 192/240 ...\n",
            "Generating image for frame 193/240 ...\n",
            "Generating image for frame 194/240 ...\n",
            "Generating image for frame 195/240 ...\n",
            "Generating image for frame 196/240 ...\n",
            "Generating image for frame 197/240 ...\n",
            "Generating image for frame 198/240 ...\n",
            "Generating image for frame 199/240 ...\n",
            "Generating image for frame 200/240 ...\n",
            "Generating image for frame 201/240 ...\n",
            "Generating image for frame 202/240 ...\n",
            "Generating image for frame 203/240 ...\n",
            "Generating image for frame 204/240 ...\n",
            "Generating image for frame 205/240 ...\n",
            "Generating image for frame 206/240 ...\n",
            "Generating image for frame 207/240 ...\n",
            "Generating image for frame 208/240 ...\n",
            "Generating image for frame 209/240 ...\n",
            "Generating image for frame 210/240 ...\n",
            "Generating image for frame 211/240 ...\n",
            "Generating image for frame 212/240 ...\n",
            "Generating image for frame 213/240 ...\n",
            "Generating image for frame 214/240 ...\n",
            "Generating image for frame 215/240 ...\n",
            "Generating image for frame 216/240 ...\n",
            "Generating image for frame 217/240 ...\n",
            "Generating image for frame 218/240 ...\n",
            "Generating image for frame 219/240 ...\n",
            "Generating image for frame 220/240 ...\n",
            "Generating image for frame 221/240 ...\n",
            "Generating image for frame 222/240 ...\n",
            "Generating image for frame 223/240 ...\n",
            "Generating image for frame 224/240 ...\n",
            "Generating image for frame 225/240 ...\n",
            "Generating image for frame 226/240 ...\n",
            "Generating image for frame 227/240 ...\n",
            "Generating image for frame 228/240 ...\n",
            "Generating image for frame 229/240 ...\n",
            "Generating image for frame 230/240 ...\n",
            "Generating image for frame 231/240 ...\n",
            "Generating image for frame 232/240 ...\n",
            "Generating image for frame 233/240 ...\n",
            "Generating image for frame 234/240 ...\n",
            "Generating image for frame 235/240 ...\n",
            "Generating image for frame 236/240 ...\n",
            "Generating image for frame 237/240 ...\n",
            "Generating image for frame 238/240 ...\n",
            "Generating image for frame 239/240 ...\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from './samples/frames/frame%04d.png':\n",
            "  Duration: 00:00:09.60, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 512x512, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mprofile High, level 3.0\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to './samples/interpolation-linear-100.0dia-seed_0-24fps.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 512x512, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame=  240 fps= 58 q=-1.0 Lsize=     597kB time=00:00:09.87 bitrate= 494.9kbits/s speed=2.37x    \n",
            "video:595kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.296030%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mframe I:1     Avg QP:21.54  size: 17633\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mframe P:239   Avg QP:21.60  size:  2472\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mmb I  I16..4:  5.4% 71.8% 22.9%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mmb P  I16..4:  0.3%  0.1%  0.0%  P16..4: 39.9%  5.9%  7.5%  0.0%  0.0%    skip:46.3%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0m8x8 transform intra:53.6% inter:68.6%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mcoded y,uvDC,uvAC intra: 47.4% 40.5% 10.0% inter: 19.5% 14.0% 0.1%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mi16 v,h,dc,p: 36% 15% 27% 22%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23%  9% 22%  6%  8% 13%  6%  9%  4%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25%  9%  7%  8% 12% 15%  9%  8%  6%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mi8c dc,h,v,p: 67% 11% 18%  5%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mref P L0: 80.4% 14.0%  4.7%  1.0%\n",
            "\u001b[1;36m[libx264 @ 0x558114173e00] \u001b[0mkb/s:486.70\n"
          ]
        }
      ]
    }
  ]
}