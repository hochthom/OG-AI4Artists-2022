{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hochthom/OG-AI4Artists-2022/blob/main/Image_Generation/StyleGAN2_ADA_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BLQf9vV1mZg"
      },
      "source": [
        "# Training StyleGAN2 on Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX5cNdvj3AuT"
      },
      "source": [
        "First we check for what GPU we have been assigned. The newer the model the faster the training will go on!\n",
        "\n",
        "- T4, Turing, 2018, 16GB\n",
        "- V100, Volta, 2017, 16GB\n",
        "- P100, Pascal, 2016, 16GB\n",
        "- K80, Kepler, 2014, 12GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJIGIZ0R1lFF",
        "outputId": "5b09e902-add7-418c-bc8b-d2012f040329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-112b3b6c-fcfe-c891-3e04-eeceb3baef09)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb0eecj73Dvv"
      },
      "source": [
        "Next we connect to Google drive account:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqoFvnYZ2Kzy",
        "outputId": "5a252c22-5713-44b4-8552-3f1fc2613993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kopih-124PSs",
        "outputId": "d6f4060f-522a-4fad-f88b-b488eb5289aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-2gaQ4uHz-i",
        "outputId": "fbc12fbe-b736-4dc8-d2be-09f635de8f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 37.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 42.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 29.7 MB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.4.2-py3-none-any.whl (17 kB)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, opensimplex, ninja\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed ninja-1.10.2.3 opensimplex-0.4.2 torch-1.7.1 torchvision-0.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja opensimplex torch==1.7.1 torchvision==0.8.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlrMOMTb5GJG"
      },
      "source": [
        "# Install StyleGAN2 Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKEn89ps3bKy",
        "outputId": "a7faeb99-43cf-47cf-8a97-bdaa2b2523a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'AI for Artists - Img-Gen.gslides'    notebooks\n",
            "'AI for Artists - Intro.gslides'      stylegan2-ada-pytorch\n",
            "'AI for Artists - Text-Gen.gslides'\n"
          ]
        }
      ],
      "source": [
        "HOME_DIR = '/content/drive/MyDrive/AI4Artists/OG-AI4Artists-2022'\n",
        "!ls $HOME_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmDlm1Kb4_B0",
        "outputId": "ecc7f5f2-c79a-4c80-a071-f67cc5654ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI4Artists/OG-AI4Artists-2022/stylegan2-ada-pytorch\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "sg2_dir = os.path.join(HOME_DIR, 'stylegan2-ada-pytorch')\n",
        "if os.path.isdir(sg2_dir):\n",
        "    %cd $sg2_dir\n",
        "elif os.path.isdir(HOME_DIR):\n",
        "    #install script\n",
        "    %cd $HOME_DIR\n",
        "    !git clone https://github.com/hochthom/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !mkdir samples\n",
        "else:\n",
        "  print('Set valid directory for HOME_DIR!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7crSGxs6ydE",
        "outputId": "0984679d-bd1b-4a95-a0ef-ac44cd4959e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apply_factor.py\t\t      Network_Blending_ADA_PT.ipynb\n",
            "blend_models.py\t\t      pbaylies_projector.py\n",
            "calc_metrics.py\t\t      pretrained\n",
            "closed_form_factorization.py  projector.py\n",
            "combine_npz.py\t\t      __pycache__\n",
            "datasets\t\t      README.md\n",
            "dataset_tool.py\t\t      results\n",
            "dnnlib\t\t\t      samples\n",
            "Dockerfile\t\t      SG2-ADA-PT_AudioReactive+Pitch.ipynb\n",
            "docker_run.sh\t\t      SG2_ADA_PT_to_Rosinality.ipynb\n",
            "docs\t\t\t      SG2_ADA_PyTorch.ipynb\n",
            "downloads\t\t      StyleCLIP_playground.ipynb\n",
            "export_weights.py\t      StyleGAN2_CLIP_approach_v1.ipynb\n",
            "flesh_digression.py\t      style_mixing.py\n",
            "generate.py\t\t      torch_utils\n",
            "legacy.py\t\t      training\n",
            "LICENSE.txt\t\t      train.py\n",
            "metrics\t\t\t      util\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_QF6fA8Xqt"
      },
      "source": [
        "# Dataset Preparation\n",
        "Upload your images in one zip file to the dataset folder in your local repo (the one we just generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx-6f90j8or6"
      },
      "source": [
        "# Model Training\n",
        "First we have to set some variables ...\n",
        "\n",
        "* `dataset_path`: this is the path to your .zip file\n",
        "* `resume_from`: if you’re starting a new dataset I recommend `'ffhq256'` or `'./pretrained/wikiart.pkl'`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G-QTs4tt8nGh"
      },
      "outputs": [],
      "source": [
        "#required: definitely edit these!\n",
        "#dataset_path = './datasets/metFaces_256.zip'\n",
        "dataset_path = './datasets/abstract_512.zip'\n",
        "#resume_from = 'noresume'  # 'ffhq256'\n",
        "resume_from = './results/00005-abstract_512-mirror-auto1-gamma10-bg-noresume/network-snapshot-000064.pkl'\n",
        "mirror_x = True\n",
        "mirror_y = False\n",
        "\n",
        "#optional: you might not need to edit these\n",
        "gamma = 10.0\n",
        "augs = 'bg'\n",
        "#config = '11gb-gpu'  # for 512x512 images or greater on a K80\n",
        "config = 'auto'      # otherwise (and for 256x256 images)\n",
        "snapshot = 4\n",
        "\n",
        "# for resuming training set this values accordingly\n",
        "aug_strength = 0.094\n",
        "train_count = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpFab8UN945G"
      },
      "source": [
        "To see all available parameters for training you can execute the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh8EEpLZ-HBu"
      },
      "outputs": [],
      "source": [
        "!python train.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3VYTfnmEk-Y",
        "outputId": "2fae2509-e827-4dd0-8a6f-89116b48349d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 4,\n",
            "  \"network_snapshot_ticks\": 4,\n",
            "  \"metrics\": [],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./datasets/abstract_512.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1000,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 512\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 32768,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 10.0\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 8,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"ema_kimg\": 2.5,\n",
            "  \"ema_rampup\": null,\n",
            "  \"nimg\": 64000,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_p\": 0.094,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"./results/00005-abstract_512-mirror-auto1-gamma10-bg-noresume/network-snapshot-000064.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"./results/00006-abstract_512-mirror-auto1-gamma10-bg-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   ./results/00006-abstract_512-mirror-auto1-gamma10-bg-resumecustom\n",
            "Training data:      ./datasets/abstract_512.zip\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1000\n",
            "Image resolution:   512\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  2000\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "starting G epochs:  0.256\n",
            "Resuming from \"./results/00005-abstract_512-mirror-auto1-gamma10-bg-noresume/network-snapshot-000064.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape        Datatype\n",
            "---                   ---         ---      ---                 ---     \n",
            "mapping.fc0           262656      -        [8, 512]            float32 \n",
            "mapping.fc1           262656      -        [8, 512]            float32 \n",
            "mapping               -           512      [8, 16, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [8, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [8, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [8, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [8, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [8, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [8, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [8, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [8, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [8, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [8, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [8, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [8, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [8, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [8, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [8, 512, 32, 32]    float32 \n",
            "synthesis.b32.conv1   2622465     1040     [8, 512, 32, 32]    float32 \n",
            "synthesis.b32.torgb   264195      -        [8, 3, 32, 32]      float32 \n",
            "synthesis.b32:0       -           16       [8, 512, 32, 32]    float32 \n",
            "synthesis.b32:1       -           -        [8, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   2622465     4112     [8, 512, 64, 64]    float16 \n",
            "synthesis.b64.conv1   2622465     4112     [8, 512, 64, 64]    float16 \n",
            "synthesis.b64.torgb   264195      -        [8, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [8, 512, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [8, 512, 64, 64]    float32 \n",
            "synthesis.b128.conv0  1442561     16400    [8, 256, 128, 128]  float16 \n",
            "synthesis.b128.conv1  721409      16400    [8, 256, 128, 128]  float16 \n",
            "synthesis.b128.torgb  132099      -        [8, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [8, 256, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [8, 256, 128, 128]  float32 \n",
            "synthesis.b256.conv0  426369      65552    [8, 128, 256, 256]  float16 \n",
            "synthesis.b256.conv1  213249      65552    [8, 128, 256, 256]  float16 \n",
            "synthesis.b256.torgb  66051       -        [8, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [8, 128, 256, 256]  float16 \n",
            "synthesis.b256:1      -           -        [8, 128, 256, 256]  float32 \n",
            "synthesis.b512.conv0  139457      262160   [8, 64, 512, 512]   float16 \n",
            "synthesis.b512.conv1  69761       262160   [8, 64, 512, 512]   float16 \n",
            "synthesis.b512.torgb  33027       -        [8, 3, 512, 512]    float16 \n",
            "synthesis.b512:0      -           16       [8, 64, 512, 512]   float16 \n",
            "synthesis.b512:1      -           -        [8, 64, 512, 512]   float32 \n",
            "---                   ---         ---      ---                 ---     \n",
            "Total                 28700647    699904   -                   -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape        Datatype\n",
            "---            ---         ---      ---                 ---     \n",
            "b512.fromrgb   256         16       [8, 64, 512, 512]   float16 \n",
            "b512.skip      8192        16       [8, 128, 256, 256]  float16 \n",
            "b512.conv0     36928       16       [8, 64, 512, 512]   float16 \n",
            "b512.conv1     73856       16       [8, 128, 256, 256]  float16 \n",
            "b512           -           16       [8, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [8, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [8, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [8, 256, 128, 128]  float16 \n",
            "b256           -           16       [8, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [8, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [8, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [8, 512, 64, 64]    float16 \n",
            "b128           -           16       [8, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]    float16 \n",
            "b64            -           16       [8, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]    float32 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]    float32 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]    float32 \n",
            "b32            -           16       [8, 512, 16, 16]    float32 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]      float32 \n",
            "b16            -           16       [8, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]      float32 \n",
            "b8             -           16       [8, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [8, 512]            float32 \n",
            "b4.out         513         -        [8, 1]              float32 \n",
            "---            ---         ---      ---                 ---     \n",
            "Total          28982849    480      -                   -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 64.0     time 1m 22s       sec/tick 13.5    sec/kimg 1685.66 maintenance 68.8   cpumem 5.25   gpumem 10.40  augment 0.094\n",
            "tick 1     kimg 68.0     time 17m 33s      sec/tick 964.3   sec/kimg 241.09  maintenance 6.3    cpumem 5.76   gpumem 7.57   augment 0.130\n",
            "tick 2     kimg 72.0     time 33m 42s      sec/tick 968.7   sec/kimg 242.17  maintenance 0.2    cpumem 5.74   gpumem 7.62   augment 0.158\n",
            "tick 3     kimg 76.0     time 49m 53s      sec/tick 970.6   sec/kimg 242.65  maintenance 0.3    cpumem 5.74   gpumem 7.50   augment 0.184\n",
            "tick 4     kimg 80.0     time 1h 06m 07s   sec/tick 973.9   sec/kimg 243.46  maintenance 0.3    cpumem 5.74   gpumem 7.50   augment 0.204\n",
            "tick 5     kimg 84.0     time 1h 22m 26s   sec/tick 973.1   sec/kimg 243.27  maintenance 6.0    cpumem 5.57   gpumem 7.61   augment 0.224\n",
            "tick 6     kimg 88.0     time 1h 38m 39s   sec/tick 973.0   sec/kimg 243.26  maintenance 0.3    cpumem 5.57   gpumem 7.60   augment 0.240\n",
            "tick 7     kimg 92.0     time 1h 54m 53s   sec/tick 973.9   sec/kimg 243.48  maintenance 0.3    cpumem 5.57   gpumem 7.54   augment 0.264\n",
            "tick 8     kimg 96.0     time 2h 11m 09s   sec/tick 975.1   sec/kimg 243.79  maintenance 0.2    cpumem 5.57   gpumem 7.57   augment 0.278\n",
            "tick 9     kimg 100.0    time 2h 27m 29s   sec/tick 974.0   sec/kimg 243.49  maintenance 6.7    cpumem 5.93   gpumem 7.65   augment 0.297\n",
            "tick 10    kimg 104.0    time 2h 43m 47s   sec/tick 976.9   sec/kimg 244.23  maintenance 0.3    cpumem 5.93   gpumem 7.59   augment 0.313\n",
            "tick 11    kimg 108.0    time 3h 00m 04s   sec/tick 976.8   sec/kimg 244.21  maintenance 0.3    cpumem 5.93   gpumem 7.55   augment 0.333\n",
            "tick 12    kimg 112.0    time 3h 16m 22s   sec/tick 978.0   sec/kimg 244.49  maintenance 0.3    cpumem 5.93   gpumem 7.58   augment 0.342\n",
            "tick 13    kimg 116.0    time 3h 32m 46s   sec/tick 977.9   sec/kimg 244.47  maintenance 6.6    cpumem 5.97   gpumem 7.56   augment 0.354\n",
            "tick 14    kimg 120.0    time 3h 49m 04s   sec/tick 977.4   sec/kimg 244.36  maintenance 0.3    cpumem 5.97   gpumem 7.62   augment 0.364\n",
            "tick 15    kimg 124.0    time 4h 05m 22s   sec/tick 977.9   sec/kimg 244.47  maintenance 0.3    cpumem 5.97   gpumem 7.60   augment 0.376\n",
            "tick 16    kimg 128.0    time 4h 21m 40s   sec/tick 977.4   sec/kimg 244.35  maintenance 0.3    cpumem 5.97   gpumem 7.56   augment 0.388\n",
            "tick 17    kimg 132.0    time 4h 38m 03s   sec/tick 977.7   sec/kimg 244.42  maintenance 5.8    cpumem 5.96   gpumem 7.58   augment 0.400\n",
            "tick 18    kimg 136.0    time 4h 54m 23s   sec/tick 979.0   sec/kimg 244.74  maintenance 0.2    cpumem 5.96   gpumem 7.67   augment 0.405\n",
            "tick 19    kimg 140.0    time 5h 10m 41s   sec/tick 977.9   sec/kimg 244.48  maintenance 0.3    cpumem 5.96   gpumem 7.66   augment 0.419\n",
            "tick 20    kimg 144.0    time 5h 27m 01s   sec/tick 980.1   sec/kimg 245.03  maintenance 0.3    cpumem 5.97   gpumem 7.66   augment 0.425\n",
            "tick 21    kimg 148.0    time 5h 43m 27s   sec/tick 980.0   sec/kimg 244.99  maintenance 6.2    cpumem 5.91   gpumem 7.65   augment 0.438\n",
            "tick 22    kimg 152.0    time 5h 59m 47s   sec/tick 980.0   sec/kimg 245.00  maintenance 0.3    cpumem 5.91   gpumem 7.63   augment 0.450\n",
            "tick 23    kimg 156.0    time 6h 16m 08s   sec/tick 980.2   sec/kimg 245.06  maintenance 0.3    cpumem 5.91   gpumem 7.70   augment 0.455\n",
            "tick 24    kimg 160.0    time 6h 32m 29s   sec/tick 980.9   sec/kimg 245.23  maintenance 0.3    cpumem 5.91   gpumem 7.65   augment 0.465\n",
            "tick 25    kimg 164.0    time 6h 48m 55s   sec/tick 980.2   sec/kimg 245.04  maintenance 6.0    cpumem 5.84   gpumem 7.63   augment 0.468\n",
            "tick 26    kimg 168.0    time 7h 05m 16s   sec/tick 980.5   sec/kimg 245.13  maintenance 0.2    cpumem 5.84   gpumem 7.67   augment 0.480\n",
            "tick 27    kimg 172.0    time 7h 21m 38s   sec/tick 981.3   sec/kimg 245.32  maintenance 0.3    cpumem 5.84   gpumem 7.67   augment 0.485\n",
            "tick 28    kimg 176.0    time 7h 38m 00s   sec/tick 982.5   sec/kimg 245.61  maintenance 0.3    cpumem 5.84   gpumem 7.70   augment 0.490\n",
            "tick 29    kimg 180.0    time 7h 54m 28s   sec/tick 981.4   sec/kimg 245.34  maintenance 6.4    cpumem 6.03   gpumem 7.63   augment 0.495\n",
            "tick 30    kimg 184.0    time 8h 10m 51s   sec/tick 982.4   sec/kimg 245.61  maintenance 0.3    cpumem 6.03   gpumem 7.61   augment 0.497\n",
            "tick 31    kimg 188.0    time 8h 27m 13s   sec/tick 982.2   sec/kimg 245.55  maintenance 0.3    cpumem 6.03   gpumem 7.66   augment 0.506\n",
            "tick 32    kimg 192.0    time 8h 43m 36s   sec/tick 982.9   sec/kimg 245.72  maintenance 0.3    cpumem 6.03   gpumem 7.72   augment 0.512\n",
            "tick 33    kimg 196.0    time 9h 00m 05s   sec/tick 982.8   sec/kimg 245.71  maintenance 5.8    cpumem 6.04   gpumem 7.70   augment 0.516\n"
          ]
        }
      ],
      "source": [
        "!python train.py --gpus=1 --cfg=auto --outdir=./results --data=$dataset_path --snap=$snapshot --resume=$resume_from --metrics=None --augpipe=$augs --gamma=$gamma --mirror=$mirror_x --mirrory=$mirror_y --initstrength=$aug_strength --nkimg=$train_count"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "StyleGAN2_ADA_Training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0icuK7suJsBFjIlo5+lI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}